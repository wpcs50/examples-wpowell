---
title: "P2: Vehicle Availability"
format: 
  html:
    theme: minty
    toc: true
    toc-location: left
editor: visual
---

The purpose of this assignment is for you to get some experience estimating and interpreting a discrete choice model by

-   Reading the documentation for the vehicle availability submodel of the Boston Region Metropolitan Planning Organization's regional travel demand model ([TDM23](https://www.ctps.org/travel-demand-model)),

-   Estimating a vehicle availability model using data using similar predictors to those in the TDM23 vehicle availability submodel and data from the 2017 National Household Travel Survey,

-   Proposing an alternative vehicle availability model for the 2017 National Household Travel Survey,

-   Comparing the accuracy and reliability of the two models,

-   Interpreting the model results to explain the influence that household and built-environment characteristics have on vehicle availability.

## Load libraries

This analysis uses the following packages:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(mlogit)
library(knitr)
library(caret)
```

There are also a couple of functions that may be helpful in working with the `mlogit` package in the `mlogit_helpers.R` file in the GitHub repo. You can load those by sourcing the file.

```{r}
here("code",
     "mlogit_helpers.R") |>
  source()
```

And here's a function that will be useful in selecting rows of a dataset based on their ID value not being in a specified list.

```{r}
'%!in%' <- function(x,y)!('%in%'(x,y))
```

## Load dataset

This analysis uses household-level data from the 2017 National Household Travel Survey.

```{r}
hh_data <- here("data",
                "NHTS",
                "hhpub.csv") |>
  read_csv(show_col_types = FALSE)

hh_data_full <- hh_data
```

The NHTS also includes person-level, trip-level, and vehicle-level datasets. You could use these to construct household-level variables if you want to, but they aren't included in the GitHub repository because the files are larger than 50 MB. To use those files, go to <https://nhts.ornl.gov/assets/2016/download/csv.zip>, extract the downloaded files, and save the four csv files (hhpub, perpub, trippub, and vehpub) to the "data" subfolder within the "examples" folder.

Once you've done that, you can load person-level data.

```{r}
person_data <- here("data",
                    "NHTS",
                    "perpub.csv") |>
  read_csv(show_col_types = FALSE)
```

## Choose variables

Refer to the TDM23 Structures and Performance report (<https://ctps.org/pub/tdm23_sc/tdm23.1.0/TDM23_Structures%20and%20Performance.pdf>) for details on the vehicle availability sub-model of the TDM23 model (beginning on page 65).

They predict vehicle availability in one of three categories:

-   Zero vehicles

-   Insufficient vehicles (fewer vehicles than drivers)

-   Sufficient vehicles (at least as many vehicles as drivers)

We will use a similar outcome variable in our model.

Their model includes the following predictors:

-   Household-level variables

    -   Number of workers

    -   Number of children

    -   Number of seniors

    -   Number of drivers (beyond two)

    -   Presence of a third driver

    -   Presence of a non-worker driver

    -   Low-income (income less than 200% of federal poverty level) (2010 dollars):

        -   One person: \$22,288

        -   Two person: \$30,060

        -   Three person: \$35,137

        -   Four person: \$45,718

        -   Five person: \$55,036

        -   Six person: \$62,641

        -   Seven person: \$72,239

        -   Eight or more person: \$81,002

    -   High-income (income greater than \$100,000 in 2010 dollars)

-   Neighborhood-level variables

    -   CBD or dense urban

        -   CBD defined as a zone with multiple heavy rail stations within a 1/2 mile

        -   Dense urban defined as a zone with at least 10,000 people or jobs per square mile

    -   Intersection density

    -   Suburban or rural

        -   Defined as a zone with fewer than 5,000 people or jobs per square mile (suburban zones have bus service and rural zones do not)

    -   Ratio of transit accessibility to highway accessibility

        -   The number of jobs accessible within 30 minutes by transit divided by the number of jobs accessible within 30 minutes by car.

For my initial model, I will follow this approach as closely as possible. The public NHTS dataset does not have information on employment density, intersection density, or accessibility, so I will estimate a model with the same outcome as the TDM23 model, using the following predictors:

-   Household-level variables

    -   Number of workers

    -   Number of children

    -   Number of seniors

    -   Number of drivers (beyond two)

    -   Presence of a third driver

    -   Presence of a non-worker driver

    -   Low-income (income less than 200% of federal poverty level - adjusted based on available categories) (2017 dollars):

        -   One person: \$25,000

        -   Two or three person: \$35,000

        -   Four or five person: \$50,000

        -   Six or seven person: \$75,000

        -   Eight or more person: \$100,000

    -   High-income (income greater than \$125,000 in 2017 dollars)

-   Neighborhood-level variables

    -   Density greater than 10,000 residents per square mile

    -   Density less than 7,000 residents per square mile

## Construct variables

You can browse descriptions of the variables available from the 2017 NHTS here: <https://nhts.ornl.gov/tables09/CodebookBrowser.aspx>

Some of these variables are directly available. We'll need to construct some of the others.

The variables we have in the household file that we can use are:

-   WRKCOUNT: The number of workers in the household. This corresponds directly to the number of workers variable.

-   DRVRCNT: The number of drivers in the household. We can use this to calculate the number of drivers beyond two, the presence of a third driver, and whether the number of vehicles per driver is less than, greater than, or equal to one.

-   HHSIZE: The number of people in the household. We can use this to calculate the number of children in the household and whether a household is low income.

-   NUMADULT: The number of adults in the household. We can use this to calculate the number of children in the household.

-   HHFAMINC: The household income, in one of 11 categories. We can use this to identify households as high income or low income.

-   HBPPOPDN: The density of the household's census block group. We can use this to classify household's neighborhoods as high- or low-density.

-   HOUSEID: A unique identifier for each household. We'll need to use this to match households to any variables we construct using person-level data.

```{r}
hh_data <- hh_data |>
  select(WRKCOUNT,
         DRVRCNT,
         HHVEHCNT,
         HHSIZE,
         NUMADLT,
         HHFAMINC,
         HBPPOPDN,
         HOUSEID)
```

We will need the person file to get the number of seniors in each household and to identify households in which all drivers are workers (the household file has the number of workers and the number of drivers, but does not necessarily tell us whether the workers and drivers are the same people).

We will need to use the following variables from the person file:

-   HOUSEID: A unique identifier for each household. We'll need to use this to match households to the data from the household-level dataset.

-   R_AGE: The person's age. We can use this to identify which household members are seniors (which we'll define as those older than 64).

-   WORKER: Whether the person is a worker.

-   DRIVER: Whether the person is a driver.

```{r}
person_data <- person_data |>
  select(HOUSEID,
         R_AGE,
         WORKER,
         DRIVER)
```

### Outcome: Vehicle availability

Our vehicle availability outcome will be a categorical variable with three categories:

-   Zero vehicles

-   Insufficient vehicles (fewer vehicles than drivers)

-   Sufficient vehicles (at least as many vehicles as drivers)

```{r}
hh_data <- hh_data |>
  mutate(veh_avail = case_when(HHVEHCNT == 0 ~ "Zero",
                               DRVRCNT > HHVEHCNT ~ "Insuff.",
                               TRUE ~ "Suff."))
```

### Predictor: Number of children

The household dataset has the number of people and the number of adults in each household, so we can take the difference as the number of children.

```{r}
hh_data <- hh_data |>
  mutate(n_child = HHSIZE - NUMADLT)
```

### Predictor: Number of seniors

We can get the number of seniors in each household from the person file.

```{r, message=FALSE}
n_seniors <- person_data |>
  mutate(is_senior = R_AGE > 64) |>
  group_by(HOUSEID) |>
  summarise(n_seniors = sum(is_senior))

hh_data <- hh_data |>
  left_join(n_seniors)
```

### Predictor: Presence of third driver

We want a binary variable for whether there are more than two drivers.

```{r}
hh_data <- hh_data |>
  mutate(three_drivers = DRVRCNT > 2)
```

### Predictor: Number of drivers beyond two

And then for those households who do have more than two drivers, we want to know how many more they have.

```{r}
hh_data <- hh_data |>
  mutate(n_extra_drivers = ifelse(three_drivers, DRVRCNT - 2, 0))
```

### Predictor: Income

Low-income designation depends on both income and household size. All households with income more than \$125,000 are designated as high income.

```{r}
hh_data <- hh_data |>
  mutate(HHFAMINC = as.numeric(HHFAMINC)) |>
  filter(HHFAMINC > 0) |>
  mutate(income = case_when(HHFAMINC < 4 ~ "low",
                             HHFAMINC < 5 & HHSIZE > 1 ~ "low",
                             HHFAMINC < 6 & HHSIZE > 3 ~ "low",
                             HHFAMINC < 7 & HHSIZE > 5 ~ "low",
                             HHFAMINC < 8 & HHSIZE > 7 ~ "low",
                             HHFAMINC > 8 ~ "high",
                            TRUE ~ "medium")) |>
    mutate(income = factor(income, levels = c("medium", "low", "high")))
    
```

### Predictor: Non-worker driver

Is there anyone in the household who is a driver, but not a worker?

```{r}
non_work_driver <- person_data |>
  mutate(non_work_driver = WORKER == "02" & DRIVER == "01") |>
  group_by(HOUSEID) |>
  summarise(non_work_driver = max(non_work_driver))

hh_data <- hh_data |>
  left_join(non_work_driver)
```

### Predictor: Density

Density will be in one of three categories: High, medium, and low.

```{r}
hh_data <- hh_data |>
  filter(HBPPOPDN > 0) |>
  mutate(density = case_when(HBPPOPDN < 7000 ~ "Low",
                             HBPPOPDN < 10000 ~ "High",
                             TRUE ~ "Medium"))
```

## Prepare data

### Drop the variables you won't be using

We have some variables in our dataset that we used to construct the variables we needed, but we don't need them any more. We'll keep only the variable we'll be including in our model.

```{r}
hh_data <- hh_data |>
  select(HOUSEID,
         veh_avail,
         WRKCOUNT,
         n_child,
         n_seniors,
         n_extra_drivers,
         three_drivers,
         non_work_driver,
         income,
         density)

```

### Create training and test datasets

We will train the model on half of our sample and use the other half to test our model.

I'm setting a random number seed so that my randomly-selected variable will be the same every time. You can choose any number as your seed (I'm using my childhood phone number! It was a land line!). In your own work, you should use a different seed than I'm using here.

```{r}
# Original Seed
# set.seed(3775668)

set.seed(615661801)

hh_data_train_ids <- sample(hh_data$HOUSEID, 
                        size = ceiling(nrow(hh_data)/2))

hh_data_train <- hh_data |>
  filter(HOUSEID %in% hh_data_train_ids)

hh_data_test <- hh_data |>
  filter(HOUSEID %!in% hh_data_train_ids)
```

### Create dfidx data

The mlogit package is useful for multinomial logistic regression, but it requires the data to be in a particular format (called dfidx) that includes information about which alternatives are available in each choice situation. In this case, all alternatives are available to all choosers in all choice situations and all variables describe the chooser and choice situation rather than the alternative, so you can use the function `fn_make_dfidx` in the `mlogit_helpers.R` file to reformat your data into the format that the `mlogit` package requires.

```{r}

veh_dfidx_train <- fn_make_dfidx(hh_data_train,
                                "HOUSEID",
                                "veh_avail")

veh_dfidx_test <- fn_make_dfidx(hh_data_test,
                                "HOUSEID",
                                "veh_avail")
```

## Estimate model

Now we can estimate our multinomial logistic regression using the `mlogit` function.

```{r}

model_veh <- mlogit(choice ~ 0 | 
                      WRKCOUNT +
                      n_child +
                      n_seniors +
                      n_extra_drivers +
                      three_drivers + 
                      non_work_driver +
                      income +
                      density | 0,
                           veh_dfidx_train,
                           reflevel = "Suff.")

```

And now we can take a look at the results of our model.

```{r}
summary(model_veh)
```

## Interpreting model results

The regression coefficients predict the *utility* of an alternative. The utility of an alternative relative to that of the other alternatives determines the probability of choosing that alternative. Looking the regression coefficient for the number of children is 0.2 for insufficient vehicles, and -0.12 for zero vehicles. This means that each additional child in a household increases the utility of having insufficient vehicles (relative to having sufficient vehicles) and decreases the utility of having zero vehicles (relative to having sufficient vehicles).

### Predicting probabilities

For example, what would be the predicted vehicle availability for a household with:

-   Two workers (WRKCOUNT = 2)

-   One senior (n_seniors = 1)

-   Three children (n_child = 3)

-   Three drivers (three_drivers = TRUE and n_extra_drivers = 1 and non_worker_driver = TRUE)

-   Low income (Income = "Low")

-   Low density (density = "low")

The utility of being a zero-vehicle household would be:

$$
0.20 + 2(-3.18) + 3(-0.12) + 1(-0.55) + 2(0.42) + 1(0.60) + 1(-4.13) + 1(1.99) + 1(-0.60) = -8.37
$$

The utility of being a vehicle-insufficient household would be:

$$
-4.25 + 2(0.41) + 3(0.20) + 1(0.32) + 2(0.26) + 1(0.74) + 1(1.22) + 1(0.60) + 1(-0.33) = 0.24
$$

The utility of being a vehicle-sufficient household (the reference case) would be zero.

The probability of the household having zero vehicles would be:

$$
\frac{e^{-8.37}}{e^{-8.37}+e^{0.24}+e^0} = 0.0001
$$

The probability of the household having insufficient vehicles would be:

$$
\frac{e^{0.24}}{e^{-8.37}+e^{0.24}+e^0} = 0.56
$$

The probability of the household having sufficient vehicles would be:

$$
\frac{e^{0}}{e^{-8.59}+e^{0.22}+e^0} = 0.44
$$

We can do this calculation for all the households in our test dataset using the `predict()` function.

```{r, message=FALSE}
predicts_test <- predict(model_veh, veh_dfidx_test) |>
  as.data.frame() |>
  rownames_to_column("HOUSEID") |>
  mutate(HOUSEID = as.numeric(HOUSEID)) |>
  left_join(hh_data_test)
```

And here are the first few rows of the resulting data frame, which shows the predicted probabilities from the model as well as the values for the predictors and the observed outcome.

```{r}
head(predicts_test) |>
  kable()
```

## Checking model reliability and accuracy

Now we can check how accurate and reliable our model is on the test dataset. First, I'll designate the alternative with the highest predicted probability as the "most likely" choice.

```{r}
predicts_test <- predicts_test |>
  mutate(most_likely = case_when((Suff. > Insuff.) & (Suff. > Zero) ~ "Suff.",
                                 (Zero > Insuff.) & (Zero > Suff.) ~ "Zero",
                                 TRUE ~ "Insuff.")) 
```

Now, I need to convert the `most_likely` and `veh_avail` variables from strings to factors in order for the next part to work.

```{r}
predicts_test <- predicts_test |>
  mutate(most_likely = factor(most_likely, 
                              levels = c("Suff.", "Insuff.", "Zero"))) |>
  mutate(veh_avail = factor(veh_avail,
                            levels = c("Suff.", "Insuff.", "Zero"))) |>
  mutate(correct = veh_avail == most_likely)


```

And now, I can use the `confusionMatrix` function to generate some accuracy and reliability statistics.

```{r}
confusionMatrix(data = predicts_test$most_likely,
                reference = predicts_test$veh_avail)
```

Interpreting the overall statistics (see the documentation for the ConfusionMatrix function here: <https://cran.r-project.org/web/packages/caret/caret.pdf>):

-   **Accuracy** is the percent of observations (in this case, households) that are correctly classified.

-   **No-information rate** is the accuracy you would achieve if you had no model and you just classified every household as the most common value.

-   The reported **p-value** is the likelihood that your model is performing better than a no-information model would.

Interpreting the statistics by class:

-   **Sensitivity** is the percent of actual positives that are correctly identified (if it's really a vehicle-insufficient household, how often will the mode say it is?)

-   **Specificity** is the percent of actual negatives that are correctly identified (if it isn't a vehicle-insufficient household, how often will the model say it isn't?)

-   **Positive predictive value** is the probability that a positive prediction will be correct (when the model predicts that a household is vehicle insufficient, how often is that prediction correct?)

-   **Negative predictive value** is the probability that a negative prediction will be correct (when the model predicts that a household is *not* vehicle insufficient, how often is *that* prediction correct?)

-   **Prevalence** is the percent of observations in this category

-   **Detection rate** (as used by the author of the Confusion Matrix function) is the frequency with which this category is correctly predicted by the model.

-   **Detection prevalence** (as used by the author of the Confusion Matrix function) is the frequency with which this category is predicted by the model.

-   **Balanced accuracy** is the average of sensitivity and specificity

## Your challenge:

Redo the above analysis. Your regression results are likely to slightly different than the above because you'll be using a different random number seed to draw the sample for your training dataset.

Can you estimate a vehicle availability model that performs better than this one? You might try a different set of predictor variables and/or a different form of the ones in this model (for example, you could use a continuous density variable, or more density categories).

Post your analysis code to GitHub and write a memo summarizing your work. Submit the memo via Canvas.

The memo should clearly document and explain all of your analysis decisions and interpreting the results of the preferred model to explain the influence that household and/or built-environment characteristics have on vehicle availability.

```{r}
add_data <- hh_data_full[,c("HOUSEID", "HBHTNRNT", "HOMEOWN", "RAIL")]

hh_data_2 <- hh_data |>
  left_join(add_data)

hh_data_2 <- hh_data_2 |>
    mutate(HBHTNRNT = as.numeric(HBHTNRNT)) |>
    filter(HBHTNRNT > 0) |>
    mutate(bg_rent_rate = HBHTNRNT)

hh_data_2 <- hh_data_2 |>
  mutate(HOMEOWN = as.numeric(HOMEOWN)) |>
  filter(HOMEOWN > 0) |>
  mutate(renter = case_when(HOMEOWN == 2 ~ 1,
                            TRUE ~ 0))

hh_data_2 <- hh_data_2 |>
  mutate(RAIL = as.numeric(RAIL)) |>
  filter(RAIL > 0) |>
  mutate(rail_msa = case_when(RAIL == 2 ~ 0,
                            TRUE ~ 1))
```

## Prepare data

### Drop the variables you won't be using

We have some variables in our dataset that we used to construct the variables we needed, but we don't need them any more. We'll keep only the variable we'll be including in our model.

```{r}
hh_data_2 <- hh_data_2 |>
  select(HOUSEID,
         veh_avail,
         WRKCOUNT,
         n_child,
         n_seniors,
         n_extra_drivers,
         three_drivers,
         non_work_driver,
         income,
         density,
         bg_rent_rate,
         renter,
         rail_msa)
```

### Create training and test datasets

We will train the model on half of our sample and use the other half to test our model.

I'm setting a random number seed so that my randomly-selected variable will be the same every time. You can choose any number as your seed (I'm using my childhood phone number! It was a land line!). In your own work, you should use a different seed than I'm using here.

```{r}
set.seed(615661801)

hh_data_2_train_ids <- sample(hh_data_2$HOUSEID, 
                        size = ceiling(nrow(hh_data_2)/2))

hh_data_2_train <- hh_data_2 |>
  filter(HOUSEID %in% hh_data_train_ids)

hh_data_2_test <- hh_data_2 |>
  filter(HOUSEID %!in% hh_data_train_ids)
```

### Create dfidx data

The mlogit package is useful for multinomial logistic regression, but it requires the data to be in a particular format (called dfidx) that includes information about which alternatives are available in each choice situation. In this case, all alternatives are available to all choosers in all choice situations and all variables describe the chooser and choice situation rather than the alternative, so you can use the function `fn_make_dfidx` in the `mlogit_helpers.R` file to reformat your data into the format that the `mlogit` package requires.

```{r}
veh_dfidx_train_2 <- fn_make_dfidx(hh_data_2_train,
                                "HOUSEID",
                                "veh_avail")

veh_dfidx_test_2 <- fn_make_dfidx(hh_data_2_test,
                                "HOUSEID",
                                "veh_avail")
```

## Estimate model

Now we can estimate our multinomial logistic regression using the `mlogit` function.

```{r}
model_veh_2 <- mlogit(choice ~ 0 | 
                      WRKCOUNT +
                      n_child +
                      n_seniors +
                      n_extra_drivers +
                      three_drivers + 
                      non_work_driver +
                      income +
                      density +
                      renter + 
                      rail_msa | 0,
                           veh_dfidx_train_2,
                           reflevel = "Suff.")
```

And now we can take a look at the results of our model.

```{r}
summary(model_veh_2)
```

```{r, message=FALSE}
predicts_test_2 <- predict(model_veh_2, veh_dfidx_test_2) |>
  as.data.frame() |>
  rownames_to_column("HOUSEID") |>
  mutate(HOUSEID = as.numeric(HOUSEID)) |>
  left_join(hh_data_2_test)
```

```{r}
predicts_test_2 <- predicts_test_2 |>
  mutate(most_likely = case_when((Suff. > Insuff.) & (Suff. > Zero) ~ "Suff.",
                                 (Zero > Insuff.) & (Zero > Suff.) ~ "Zero",
                                 TRUE ~ "Insuff.")) 
```

```{r}
predicts_test_2 <- predicts_test_2 |>
  mutate(most_likely = factor(most_likely, 
                              levels = c("Suff.", "Insuff.", "Zero"))) |>
  mutate(veh_avail = factor(veh_avail,
                            levels = c("Suff.", "Insuff.", "Zero"))) |>
  mutate(correct = veh_avail == most_likely)

```

```{r}
confusionMatrix(data = predicts_test_2$most_likely,
                reference = predicts_test_2$veh_avail)
```
